## ES查询原理

前面提到过，ES的查询速度很快，那么接下来就讲解一下为ES查询速度快的原理。在大量数据中查询特定的数据，那么自然就需要索引机制，常见的索引有MySQL B+数索引，Linux文件系统index文件，Kafka 索引文件，Redis Hash索引，基本上所有存储相关的中间件都有自己独特的索引机制，不然每次查询数据需要O(N)的遍历，速度极慢。

而Elasticsearch是通过**Lucene的倒排索引**技术实现比关系型数据库更快的过滤。特别是它对**多条件的过滤**支持非常好，比如年龄在18和30之间，性别为女性这样的组合查询。倒排索引很多地方都有介绍，但是其比关系型数据库的B+树索引快在哪里？到底为什么快呢？

### 什么是倒排索引

再说倒排索引之前，那么我们肯定要先来说一下什么是正排索引，举一个MySQL的例子

`select * from sys_user where id = 10086`

通过id查找对应的数据项，这个过程我们可以看做正排索引，通过Key去找Value。

那么倒排索引就是通过Value去找Key。

举个例子，有这样一组数据

```json
[
    {
	"name": "小明",
	"age": 20,
	"sex': "man"
	},
    {
	"name": "阿强",
	"age": 20,
	"sex': "man"
	},
    {
	"name": "大刚",
	"age": 21,
	"sex': "male"
	}
]

```

我们可以看到es会建立以下的索引：

**Name倒排索引**

| Term | Posting List |
| :--- | :----------: |
| 小明 |      1       |
| 阿强 |      2       |
| 大刚 |      3       |

**Size倒排索引**

| Term | Posting List |
| :--: | :----------: |
|  20  |    [1,2]     |
|  21  |      3       |

**Sex倒排索引**

| Term | Posting List |
| :--: | :----------: |
| man  |    [1,2]     |
| Male |      3       |

大家可以看到所有的倒排所有都有Term和Posting List这两个概念，Posting list就是一个int的数组，存储了所有符合某个term的文档id。

怎么根据value找key呢？就比如我要找所有性别是男生的人，Sex的倒排索引的Posting list可以告诉我是id为1和2的人，那再通过Name的term我可以看到1的是人小明，2的人是阿强，依次类推找到所有信息。

Es的查询速度是非常快的，但是目前看来如果只是以Term的样子去查找并不快呀？

根据当前的查询方式，我们需要遍历一遍所有的Term然后找到对应的Posting List，效率特别低，那么ES是怎么做的呢？

答案就是排序，MySQL就是通过将索引排序成B+树加快的查询速度，而ES将Term排序成**跳表**，来加快查询速度，通过跳表，查询的时间复杂度降低为**O(logN)**

但这还不够，ES往往存储了很多数据，如果将Term放入内存，那么肯定放不下，如果放在磁盘，那么由于磁盘IO过慢，查询速度还是很慢，那么ES是怎么做的呢？

答案是再加一层，计算机领域，没有加一层完不成的功能

<img src="http://img.jjjzzzqqq.top/image-20220508151635786.png" alt="image-20220508151635786" style="zoom: 33%;" />

这里就会引出接下来的两个概念，**Term Dictionary**和**Term Index**。

前面提到的Term构造的跳表就是Term Dictionary，而Term Index是在Term Dictionary的基础上增加了一层前缀字典树，它不存储所有的单词，只存储单词前缀，查询的时候，先通过Term Index找到查询关键词对应的磁盘块，然后再在对应的Term Dictionary区域进行二分查找，由于Term Index只存储了单词前缀，所以Term Index是有机会完全放在内存中的，那么这样查询速度就变得很快了。

​														下面用一张经典的图来表示倒排索引的数据结构

![Lucene倒排索引内部结构](https://qiniu.xiaoming.net.cn/Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84.jpg)

同时，Lucene 还用了 **FST**（Finite State Transducers）对 Term Index 做进一步**压缩**，term index 在内存中是以FST（finite state transducers）的形式保存的，其特点是非常节省内存。Term dictionary 在磁盘上是以分 block 的方式保存的，一个block 内部利用公共前缀压缩，比如都是 Ab 开头的单词就可以把 Ab 省去。

说完了倒排索引查询的原理以及它为什么这么快，我们再来说一下对于**多个条件的复杂查询**，ES是如何优化的。

什么叫多个条件的复杂查询？

还是之前那组对象：

比如现在我要查询年龄在18-20，性别为女，名字带有小的人，这就是一个求交集的复杂查询。

又比如查询年龄在18-20，或名字为小明的人，这就是一个求并集复杂查询。

其实熟悉ES查询的程序员都知道，这就是ES复杂查询中的Must和Should等功能。

那么ES就需要根据每个Term倒排索引对应的Posting List数组，求出对应的交集和并集。

那么我给大家出一个附加题：

两个无序不重复数组求交集？（腾讯二面面试题原题）

1. 暴力，A数组里的每一个数去B数组查询，如果存在就说明是交集中的数。时间复杂度O(N²)
2. 先排序后双指针，将AB排序，然后双指针从后往前遍历，由于数字有序，所以之后求的数字永远不可能在之前的遍历过程中出现相同的数字。时间复杂度O(N*logN)
3. HashMap法，将A数组中的所有数存入HashMap中，判断B的数是否在HashMap中出现过，如果出现，说明是交集中的数字。时间复杂度O(N)，空间复杂度O(N)

同样，我们把 Lucene倒排索引遇到的问题，简化成一道算法题。

假设有下面三个数组：

[64, 300, 303, 343]

[73, 300, 302, 303, 343, 372]

[303, 311, 333, 343]

求它们的交集。

**Option 1: Integer 数组**

直接用原始的文档 ID ，可能你会说，那就逐个数组遍历一遍吧，遍历完就知道交集是什么了。

其实对于有序的数组，用跳表（skip table）可以更高效，这里就不展开了，因为不管是从性能，还是空间上考虑，Integer 数组都不靠谱，假设有100M 个文档 ID，每个文档 ID 占 2 bytes，那已经是 200 MB，而这些数据是要放到内存中进行处理的，把这么大量的数据，从磁盘解压后丢到内存，内存肯定撑不住。

**Option 2: Bitmap**

假设有这样一个数组：

[3,6,7,10]

那么我们可以这样来表示：

[0,0,1,0,0,1,1,0,0,1]

看出来了么，对，**我们用 0 表示角标对应的数字不存在，用 1 表示存在。**

这样带来了两个好处：

- **节省空间**：既然我们只需要0和1，那每个文档 ID 就只需要 1 bit，还是假设有 100M 个文档，那只需要 100M bits = 100M * 1/8 bytes = 12.5 MB，比之前用 Integer 数组 的 200 MB，优秀太多
- **运算更快**：0 和 1，天然就适合进行位运算，**求交集，「与」一下**，**求并集，「或」一下**，一切都回归到计算机的起点

**Option 3: Roaring Bitmaps**

细心的你可能发现了，bitmap 有个硬伤，就是不管你有多少个文档，你占用的空间都是一样的，Lucene Posting List 的每个 Segement 最多放 65536 个文档ID，举一个极端的例子，有一个数组，里面只有两个文档 ID：

[0, 65535]

用 Bitmap，要怎么表示？

[1,0,0,0,….(超级多个0),…,0,0,1]

你需要 65536 个 bit，也就是 65536/8 = 8192 bytes，而用 Integer 数组，你只需要 2 * 2 bytes = 4 bytes

呵呵，死板的 bitmap。可见在文档数量不多的时候，使用 Integer 数组更加节省内存。

我们来算一下临界值，很简单，无论文档数量多少，bitmap都需要 8192 bytes，而 Integer 数组则和文档数量成线性相关，每个文档 ID 占 2 bytes，所以：

8192 / 2 = 4096

当文档数量少于 4096 时，用 Integer 数组，否则，用 bitmap.



**总结：为什么ES比MySQL快？**

因为加了一层  /狗头

Mysql 只有 term dictionary 这一层，是以 B+tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次（B+树层数）随机 IO 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了term index来加速检索，term index 以树的形式缓存在内存中。**从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term**，大大减少了磁盘的 random access （随机IO）次数。

### ES读写数据的原理是什么

#### ES写入数据

![es-write](http://img.jjjzzzqqq.top/es-write.png)

1. 客户端选择一个 node 发送请求过去，这个 node 就是 **coordinating node**（协调节点）。
2. `coordinating node` 对 document 进行**路由**，将请求转发给对应的 node（有 primary shard）。
3. 对应的 node 上的**主节点处理请求**，然后将**数据同步**到 `replica node` 。
4. `coordinating node` 如果发现主节点和所有副本节点都搞定之后，就返回响应结果给客户端。

#### ES读数据过程

ES读数据一般是根据doc id 来查询。

1. 客户端选择一个node发送请求，这个 node 就是 **coordinating node**（协调节点）
2. 协调节点对 doc id 进行Hash路由，将请求转发到一个node，这个node是该doc id 对应节点的主节点和副本节点集合中的一个随机节点，会通过**round-robin**算法负载均衡
3. 接收请求的节点返回给协调节点，协调节点返回给客户端

#### ES搜索数据过程

1. 客户端发送请求到一个协调节点
2. 协调节点将搜索请求**转发到所有分片**对应的  主节点和副本节点集合中的一个 ，也就是**所有分片都会有一个节点**执行搜索
3. query phase：每个节点将自己的搜索结果（其实就是一些doc id）返回给协调节点，由协调节点进行数据的合并，排序，分页等操作，产出最终结果
4. fetch phase：由协调节点根据doc id去各个节点上获取实际的 document 数据，最终返回给客户端